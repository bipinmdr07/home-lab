services:
  immich-server:
    container_name: immich-server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    user: "1000:1000"
    # extends:
    #   file: hwaccel.transcoding.yml
    #   service: cpu # set to one of [nvenc, quicksync, rkmpp, vaapi, vaapi-wsl] for accelerated transcoding
    volumes:
      - ${IMMICH_UPLOAD_PATH}/:/data
      - /etc/localtime:/etc/localtime:ro
      - shared_data:/mnt/shared
    devices:
      - /dev/dri:/dev/dri # For hardware Acceleration
    environment:
      - TZ=${TZ}
      - IMMICH_VERSION=release
      - DB_HOSTNAME=postgres
      - DB_DATABASE_NAME=immich
      - DB_USERNAME=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_STORAGE_TYPE=HDD # Options are HDD or SSD
    ports:
      - '2283:2283'
    depends_on:
      - redis
      - postgres
      - immich-machine-learning
    restart: always
    healthcheck:
      disable: false
    networks:
      - database
      - default
    labels:
      - caddy=immich.${DOMAIN:-orangepi2.box}
      - caddy.tls=internal
      - caddy.reverse_proxy={{upstreams 2283}}
      - homepage.group=Media
      - homepage.name=immich
      - homepage.icon=si-immich
      - homepage.href=https://immich.${DOMAIN:-orangepi2.box}
      - homepage.widget.type=immich
      - homepage.widget.url=http://immich-server:2283
      - homepage.widget.key=${IMMICH_API_KEY}
      - homepage.widget.version=2


  immich-machine-learning:
    container_name: immich-machine-learning
    # For hardware acceleration, add one of -[armnn, cuda, rocm, openvino, rknn] to the image tag.
    # Example tag: ${IMMICH_VERSION:-release}-cuda
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    # extends: # uncomment this section for hardware acceleration - see https://immich.app/docs/features/ml-hardware-acceleration
    #   file: hwaccel.ml.yml
    #   service: cpu # set to one of [armnn, cuda, rocm, openvino, openvino-wsl, rknn] for accelerated inference - use the `-wsl` version for WSL2 where applicable
    environment:
      # Ensure it binds to all interfaces
      - MACHINE_LEARNING_HOST=0.0.0.0
      - MACHINE_LEARNING_PORT=3003
    ports:
      # Optional: expose port for debugging
      - "3003:3003"
    volumes:
      - model-cache:/cache
      - ${IMMICH_UPLOAD_PATH}/:/data
      - shared_data:/mnt/shared
    restart: always
    networks:
      - default
    healthcheck:
      disable: false

